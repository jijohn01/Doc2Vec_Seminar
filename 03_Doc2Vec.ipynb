{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7de7BhQiGxSCLRbdRmepi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Doc2Vec 실습코드"],"metadata":{"id":"wrd5fbCZRG7Z"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"IUgH5vwhNFVe","executionInfo":{"status":"ok","timestamp":1678614352791,"user_tz":-540,"elapsed":742,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"outputs":[],"source":["import requests\n","from io import StringIO\n","import pandas as pd"]},{"cell_type":"code","source":["# 영화리뷰 데이터 다운로드\n","res = requests.get('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n","df = pd.read_csv(StringIO(res.text), sep='\\t')\n","\n","df.rename(columns={'document': 'content'}, inplace=True)\n","documents = df['content'].to_list()"],"metadata":{"id":"XhdrkVYQNf4P","executionInfo":{"status":"ok","timestamp":1678614586668,"user_tz":-540,"elapsed":411,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n","from tqdm import tqdm\n","import os\n","\n","Corpus = []\n","idx2doc = {}\n","for idx, text in tqdm(enumerate(documents), desc='데이터 로드', leave=False):\n","    idx2doc[idx] = str(text)\n","    for t in str(text).strip().split():\n","        Corpus.append(TaggedDocument(words=t, tags=[idx]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrTKc7OpNyqM","executionInfo":{"status":"ok","timestamp":1678614911194,"user_tz":-540,"elapsed":1791,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"db4a2109-a94d-416d-c342-138e85e9db74"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":[]}]},{"cell_type":"code","source":["print('Doc2vec training...')\n","model = Doc2Vec(Corpus, dm=1, vector_size=100, window=5, epochs=50, min_count=3, negative_size=5,\n","                alpha=0.025, workers=os.cpu_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olSMgfmlOEsF","outputId":"d3926023-ea51-42d2-eabd-b6fc2a1c9a6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.doc2vec:Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n"]},{"output_type":"stream","name":"stdout","text":["Doc2vec training...\n"]}]},{"cell_type":"code","source":["qry_idx = 4188\n","print('target text: {}:'.format(idx2doc[qry_idx]))\n","print(' ')\n","top_3_idx = []\n","for e in model.docvecs.most_similar(qry_idx, topn=3):\n","        doc_idx, score = e[0], e[1]\n","        print('doc_id: {}, score: {}, doc: {}'.format(doc_idx, round(score, 2), idx2doc[doc_idx]))\n","        top_3_idx.append(doc_idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNASjfQXPu8p","executionInfo":{"status":"ok","timestamp":1678615200986,"user_tz":-540,"elapsed":273,"user":{"displayName":"JiSoo Park","userId":"07675967515243731049"}},"outputId":"5812402e-4a6e-4184-e17b-af69e25eef6b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["target text: 영화 전체가 어디선가 본듯한 장면들의 짜집기...:\n"," \n","doc_id: 43646, score: 0.79, doc: 한마디로 쓰레기\n","doc_id: 9650, score: 0.79, doc: 의지가 부족한 영화\n","doc_id: 18732, score: 0.79, doc: 어디서 본듯한 내용 짜집기....재미도 그닥...\n"]}]},{"cell_type":"markdown","source":["## 차원 축소 및 시각화"],"metadata":{"id":"4kekoPnZRCp2"}},{"cell_type":"code","source":["from gensim.models.doc2vec import Doc2Vec\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","\n","# 모든 문서에 대한 벡터 가져오기\n","# vectors = [model.docvecs.vectors_docs[i] for i in range(len(model.docvecs))]\n","vectors = model.docvecs.vectors_docs\n","# PCA를 사용하여 2차원으로 축소\n","pca = PCA(n_components=2)\n","result = pca.fit_transform(vectors)\n"],"metadata":{"id":"ZB-A42PPP8Gb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 시각화\n","plt.scatter(result[:, 0], result[:, 1])\n","\n","for idx in top_3_idx:\n","    plt.scatter(result[idx, 0], result[idx, 1], color='black')\n","plt.scatter(result[qry_idx, 0], result[qry_idx, 1], color='red')\n","\n","plt.show()"],"metadata":{"id":"BTc449vRQDHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 새로운 쿼리가 있다고 가정"],"metadata":{"id":"ZSUuXj0HQLnb"}},{"cell_type":"code","source":["from gensim.utils import simple_preprocess\n","\n","new_sentence = \"배꼽 빠지게 우스웠다는 리뷰\"\n","\n","# 입력 받은 문장을 전처리\n","new_doc = new_sentence.lower().split()\n","\n","# 모델에서 추론된 벡터를 가져옴\n","inferred_vector = model.infer_vector(new_doc)\n","\n","# 가장 유사한 문서를 찾음\n","similar_doc = model.docvecs.most_similar([inferred_vector], topn=1)\n","\n","# 가장 유사한 문서와 유사도 출력\n","print(new_sentence)\n","print(\"가장 유사한 문서: \", similar_doc[0][0])\n","print(\"유사도: \", similar_doc[0][1])\n","print('sentence: ', idx2doc[similar_doc[0][0]])"],"metadata":{"id":"BGg7h2S3QFWl"},"execution_count":null,"outputs":[]}]}